import os
import subprocess
from datetime import datetime

LLAMA_CLI = "/home/k/llama.cpp/build/bin/llama-cli"
MODEL_PATH = "/home/k/llama.cpp/models/phi-2.Q4_K_M.gguf"
LOG_DIR = "logs"
LOG_FILE = os.path.join(LOG_DIR, "last_run.txt")
TEST_PROMPT = "B·∫°n l√† ai?"


def write_log(content):
    os.makedirs(LOG_DIR, exist_ok=True)
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(f"\n=== {datetime.now()} ===\n")
        f.write(content + "\n")


def check_file(path, label):
    if not os.path.isfile(path):
        msg = f"[‚ùå MISSING] {label} not found at: {path}"
        write_log(msg)
        print(msg)
        return False
    print(f"[‚úÖ FOUND] {label}")
    return True


def run_test_prompt():
    try:
        cmd = [LLAMA_CLI, "-m", MODEL_PATH, "-p", TEST_PROMPT, "--n-predict", "128"]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=60)
        output = result.stdout.strip()
        write_log("[‚úÖ PASSED] llama-cli output:\n" + output)
        print("[‚úÖ PASSED] Test prompt ran successfully. Check logs/last_run.txt")
    except subprocess.TimeoutExpired:
        msg = "[‚è∞ TIMEOUT] llama-cli ch·∫°y qu√° 60s. C√≥ th·ªÉ model ƒëang load ch·∫≠m ho·∫∑c prompt kh√¥ng r√µ.\n" \
              "‚Üí Th·ª≠ ch·∫°y th·ªß c√¥ng l·ªánh sau ƒë·ªÉ xem chi ti·∫øt:\n" \
              f"{ ' '.join(cmd) }"
        write_log(msg)
        print(msg)
    except subprocess.CalledProcessError as e:
        msg = "[‚ùå llama-cli FAILED]\n" + e.stderr.strip()
        write_log(msg)
        print(msg)
    except FileNotFoundError as e:
        msg = f"[‚ùå FileNotFoundError]\n{str(e)}"
        write_log(msg)
        print(msg)


if __name__ == "__main__":
    print("üê∂ ƒêang ki·ªÉm tra h·ªá th·ªëng C√∫n CLI...\n")
    ok = True
    ok &= check_file(LLAMA_CLI, "llama-cli")
    ok &= check_file(MODEL_PATH, "model .gguf")
    if ok:
        run_test_prompt()
    else:
        print("\n‚ö† D·ª´ng test v√¨ thi·∫øu file.")
